# Go SEO - Асинхронная система отслеживания позиций

## Обзор

Система была оптимизирована для обработки больших объемов ключевых слов (1000+) с использованием асинхронной архитектуры.

## Ключевые улучшения

### 1. Асинхронная обработка
- API endpoints теперь возвращают `task_id` и статус 200 сразу
- Обработка происходит в фоне с использованием goroutines
- Worker pool для контроля параллелизма

### 2. Батчинг ключевых слов
- Ключевые слова группируются в батчи (по умолчанию 50 штук)
- Один worker обрабатывает весь батч последовательно
- Контролируемое количество горутин (по умолчанию 10)
- Предотвращение перегрузки внешних API

### 3. Retry-механизм
- 5 попыток с экспоненциальной задержкой (10с, 20с, 40с, 80с, 160с)
- Автоматическое восстановление после сбоев внешних сервисов

### 4. Система уведомлений
- Kafka топики для отправки статусов задач
- Логирование всех операций
- Возможность интеграции с внешними системами

### 5. Оптимизация БД
- Новые таблицы для задач и результатов
- Индексы для быстрого поиска
- Партиционирование по датам

## API изменения

### Старый формат ответа:
```json
{
  "message": "Google positions tracked successfully",
  "count": 150
}
```

### Новый формат ответа:
```json
{
  "message": "Google tracking started successfully",
  "task_id": "job_abc123def456",
  "status": "pending"
}
```

## Структура базы данных

### Новые таблицы:

#### tracking_jobs
- `id` - уникальный ID задачи
- `site_id` - ID сайта
- `source` - источник (google/yandex/wordstat)
- `status` - статус (pending/running/completed/failed)
- `total_tasks` - общее количество подзадач
- `completed_tasks` - завершенные подзадачи
- `failed_tasks` - неудачные подзадачи

#### tracking_tasks
- `id` - уникальный ID подзадачи
- `job_id` - ID основной задачи
- `keyword_id` - ID ключевого слова
- `status` - статус подзадачи
- `retry_count` - количество попыток
- `max_retries` - максимальное количество попыток

#### tracking_results
- `task_id` - ID подзадачи
- `job_id` - ID основной задачи
- `keyword_id` - ID ключевого слова
- `rank` - позиция
- `success` - успешность выполнения

## Kafka топики

### tracking-status
Сообщения о статусе отдельных задач:
```json
{
  "task_id": "task_abc123",
  "job_id": "job_def456",
  "status": "completed",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### tracking-jobs
Сообщения о статусе основных задач:
```json
{
  "task_id": "job_def456",
  "job_id": "job_def456",
  "status": "completed",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

## Конфигурация

### Переменные окружения:
- `KAFKA_BROKERS` - список брокеров Kafka (по умолчанию: localhost:9092)
- `WORKER_COUNT` - количество worker'ов (по умолчанию: 10)
- `BATCH_SIZE` - размер батча ключевых слов (по умолчанию: 50)

## Архитектура батчинга

### Проблема без батчинга:
- 1000 ключевых слов = 1000 горутин
- Перегрузка системы и внешних API
- Проблемы с памятью

### Решение с батчингом:
- 1000 ключевых слов = 20 батчей по 50 ключевых слов
- Максимум 10 горутин (worker pool)
- Контролируемая нагрузка на внешние API

### Пример:
```
1000 ключевых слов:
├── Батч 1: ключевые слова 1-50   (Worker 1)
├── Батч 2: ключевые слова 51-100 (Worker 2)
├── ...
└── Батч 20: ключевые слова 951-1000 (Worker 10)
```

## Запуск

1. Установите зависимости:
```bash
go mod tidy
```

2. Настройте переменные окружения в `.env` файле

3. Запустите миграции БД:
```bash
go run cmd/migrate/main.go
```

4. Запустите сервер:
```bash
go run cmd/server/main.go
```

## Мониторинг

Система логирует все операции:
- Создание задач
- Статусы выполнения
- Ошибки и retry попытки
- Kafka сообщения

## Производительность

- Обработка до 1000+ ключевых слов одновременно
- Worker pool предотвращает перегрузку внешних API
- Retry-механизм обеспечивает надежность
- Асинхронная архитектура не блокирует API
